# LoRA-tuned DINO with NeRF Configuration
# This configuration reproduces the LoRA experiment from the paper

experiment:
  name: "LoRA-NeRF-Lego"
  description: "NeRF with LoRA-tuned DINO features"
  version: "1.0"

near: 2.0
far: 6.0

data:
  dataset: "nerf_synthetic"
  scene: "lego"
  num_views: 5
  resolution: 128

model:
  use_dino: true
  dino_model_type: 'single_scale'

nerf_model:
  pos_freq: 12
  dir_freq: 4
  hidden_dim: 256
  num_layers: 8

dino_model:
  name: "facebook/dinov2-base"
  use_lora: true
  lora_rank: 16
  lora_alpha: 16

training:
  epochs: 200
  batch_size: 512
  progressive_schedule:
    epochs_0_50: [32, 32, 32]
    epochs_50_100: [64, 64, 48]
    epochs_100_plus: [128, 128, 64]

optimizer:
  lr: 2.0e-4
  weight_decay: 1.0e-6
  lr_milestones: [80, 150]
  lr_gamma: 0.5

loss:
  rgb_weight: 1.0
  depth_weight: 0.1
  reg_weight: 0.0001

rendering:
  chunk_size: 1024
  noise_std: 0.1
  white_bkgd: false

output:
  save_dir: "results/lora_nerf_lego"
  save_freq: 50
  val_freq: 10
  log_freq: 1

# Expected results
expected_results:
  psnr: 23.3
  ssim: 0.58
  lpips: 0.25
  training_time: "3.2h" 